"""
å°† ShareGPT æ ¼å¼çš„è®­ç»ƒæ•°æ®è½¬æ¢ä¸º OpenAI fine-tuning JSONL æ ¼å¼ã€‚
ç²¾é€‰å‡è¡¡ã€é«˜è´¨é‡çš„æ ·æœ¬ã€‚

OpenAI æ ¼å¼:
{"messages": [{"role": "system", "content": "..."}, {"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}, ...]}
"""
import json
import random
import sys
import tiktoken
from collections import Counter

random.seed(42)

INPUT = "./training_data/sft-joker-clean.json"
OUTPUT = "./training_data/openai-finetune.jsonl"
SAMPLES_PER_TYPE = 60
MAX_TOKENS_PER_EXAMPLE = 4096


def sharegpt_to_openai(conv: dict) -> dict:
    """ShareGPT â†’ OpenAI messages æ ¼å¼"""
    messages = []
    for msg in conv["conversations"]:
        if msg["from"] == "system":
            messages.append({"role": "system", "content": msg["value"]})
        elif msg["from"] == "human":
            messages.append({"role": "user", "content": msg["value"]})
        elif msg["from"] == "gpt":
            messages.append({"role": "assistant", "content": msg["value"]})
    # OpenAI è¦æ±‚æœ€åä¸€æ¡å¿…é¡»æ˜¯ assistant
    while messages and messages[-1]["role"] != "assistant":
        messages.pop()
    return {"messages": messages}


def count_tokens(messages: list, encoding) -> int:
    total = 0
    for msg in messages:
        total += 4  # <im_start>, role, \n, <im_end>
        total += len(encoding.encode(msg["content"]))
    total += 2  # <im_start>assistant prefix
    return total


def quality_score(conv: dict) -> float:
    """ç®€å•è¯„åˆ†ï¼šä¼˜å…ˆé€‰å¤šè½®ã€é•¿åº¦é€‚ä¸­ã€æœ‰å®è´¨å†…å®¹çš„å¯¹è¯"""
    msgs = conv["conversations"]
    gpt_msgs = [m for m in msgs if m["from"] == "gpt"]
    human_msgs = [m for m in msgs if m["from"] == "human"]

    n_turns = len(gpt_msgs)
    avg_len = sum(len(m["value"]) for m in gpt_msgs) / max(n_turns, 1)

    score = 0.0
    # 3-8 è½®æœ€ä½³
    if 3 <= n_turns <= 8:
        score += 2.0
    elif n_turns <= 2:
        score += 1.0  # çŸ­å¯¹è¯ä¹Ÿè¦ï¼Œä½†æƒé‡ä½ä¸€äº›
    else:
        score += 1.5

    # å›å¤å¹³å‡é•¿åº¦ 10-80 å­—æœ€è‡ªç„¶
    if 10 <= avg_len <= 80:
        score += 2.0
    elif avg_len < 10:
        score += 0.5
    else:
        score += 1.0

    # æœ‰å®é™…å†…å®¹çš„åŠ åˆ†
    all_gpt = " ".join(m["value"] for m in gpt_msgs)
    if any(w in all_gpt for w in ["MF", "æ•°å­¦", "INFP", "å†™æ­Œ", "çœ‹ç•ª", "ç‚’è‚¡", "éª‘è½¦"]):
        score += 1.0

    # æœ‰è‡ªç„¶å£è¯­åŒ–è¡¨è¾¾çš„åŠ åˆ†
    if any(w in all_gpt for w in ["ç´ ", "ç¬‘æ­»", "æˆ‘å‹’ä¸ªè±†", "emmmm", "å¥½å¥½å¥½", "ğŸ‰‘"]):
        score += 1.0

    return score


def main():
    with open(INPUT, "r", encoding="utf-8") as f:
        data = json.load(f)
    print(f"åŸå§‹æ•°æ®: {len(data)} æ¡")

    try:
        encoding = tiktoken.encoding_for_model("gpt-4o")
    except Exception:
        encoding = tiktoken.get_encoding("cl100k_base")

    # æŒ‰ç±»å‹åˆ†ç»„
    by_type: dict[str, list] = {}
    for conv in data:
        style = conv.get("style", "default")
        by_type.setdefault(style, []).append(conv)

    print("\nå„ç±»å‹æ•°é‡:")
    for k, v in sorted(by_type.items(), key=lambda x: -len(x[1])):
        print(f"  {k}: {len(v)}")

    # æ¯ç§ç±»å‹æŒ‰è´¨é‡è¯„åˆ†æ’åºï¼Œé€‰ top N
    selected = []
    for style, convs in by_type.items():
        scored = [(quality_score(c), random.random(), c) for c in convs]
        scored.sort(key=lambda x: (-x[0], x[1]))

        count = 0
        for _, _, conv in scored:
            if count >= SAMPLES_PER_TYPE:
                break
            openai_fmt = sharegpt_to_openai(conv)
            tokens = count_tokens(openai_fmt["messages"], encoding)
            if tokens <= MAX_TOKENS_PER_EXAMPLE:
                selected.append(openai_fmt)
                count += 1
        print(f"  {style}: é€‰å– {count} æ¡")

    random.shuffle(selected)

    # ç»Ÿè®¡ token
    total_tokens = sum(count_tokens(s["messages"], encoding) for s in selected)

    with open(OUTPUT, "w", encoding="utf-8") as f:
        for item in selected:
            f.write(json.dumps(item, ensure_ascii=False) + "\n")

    print(f"\nè¾“å‡º: {OUTPUT}")
    print(f"æ€»æ¡æ•°: {len(selected)}")
    print(f"æ€» token: {total_tokens:,}")
    print(f"é¢„ä¼°è®­ç»ƒè´¹ç”¨ (GPT-4o-mini): ~${total_tokens * 8 / 1_000_000:.2f}")
    print(f"é¢„ä¼°è®­ç»ƒè´¹ç”¨ (GPT-4o):      ~${total_tokens * 25 / 1_000_000:.2f}")

    # éªŒè¯åˆ†å¸ƒ
    role_dist = Counter()
    for item in selected:
        for msg in item["messages"]:
            if msg["role"] == "system":
                content = msg["content"]
                if "å…„å¼Ÿ" in content and "æš—æ‹" not in content and "å‰ä»»" not in content:
                    role_dist["brother"] += 1
                elif "æš—æ‹" in content:
                    role_dist["crush"] += 1
                elif "å‰ä»»" in content:
                    role_dist["ex"] += 1
                elif "å¥³ç”Ÿæœ‹å‹" in content:
                    role_dist["female_friend"] += 1
                else:
                    role_dist["default"] += 1
                break

    print(f"\nå…³ç³»ç±»å‹åˆ†å¸ƒ: {dict(role_dist)}")


if __name__ == "__main__":
    main()
